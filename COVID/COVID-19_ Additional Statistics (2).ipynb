{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\nfrom plotly.subplots import make_subplots\n\nfrom pathlib import Path\ndata_dir = Path('../input/')\n\nimport os\nos.listdir(data_dir)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/covid19-global-forecasting-week-3/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/covid19-global-forecasting-week-3/train.csv')\ndf.rename(columns={'Country_Region' : 'country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/covid19-global-forecasting-week-3/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df , test])\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the cleaned data from https://www.kaggle.com/imdevskp/corona-virus-report."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.merge(df, countries_df, on='country')\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"icu_df = pd.read_csv(\"../input/hospital-beds-by-country/API_SH.MED.BEDS.ZS_DS2_en_csv_v2_887506.csv\")\nicu_df['Country Name'] = icu_df['Country Name'].replace('United States', 'US')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Russian Federation', 'Russia')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Iran, Islamic Rep.', 'Iran')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Egypt, Arab Rep.', 'Egypt')\nicu_df['Country Name'] = icu_df['Country Name'].replace('Venezuela, RB', 'Venezuela')\ndf['country'] = df['country'].replace('Czechia', 'Czech Republic')\n\n\n# We wish to have the most recent values, thus we need to go through every year and extract the most recent one, if it exists.\nicu_cleaned = pd.DataFrame()\nicu_cleaned[\"country\"] = icu_df[\"Country Name\"]\nicu_cleaned[\"icu\"] = np.nan\n\nfor year in range(1960, 2020):\n    year_df = icu_df[str(year)].dropna()\n    icu_cleaned[\"icu\"].loc[year_df.index] = year_df.values\n\ndf = pd.merge(df, icu_cleaned, on='country' , how = 'left')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Temperature Data\nIn our next step, we wish to analyze the weather and temperature data of the respective countries since the outbreak of the virus. We have composed a dataset here: https://www.kaggle.com/winterpierre91/covid19-global-weather-data\n\nWe hope to find some colleration between certain weather metrics and the speed of the number of infections/deaths."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df_temperature = pd.read_csv(\"../input/covid19-global-weather-data/temperature_dataframe.csv\")\ndf_temperature['country'] = df_temperature['country'].replace('USA', 'US')\ndf_temperature['country'] = df_temperature['country'].replace('UK', 'United Kingdom')\ndf_temperature = df_temperature[[\"country\", \"province\", \"date\", \"humidity\", \"sunHour\", \"tempC\", \"windspeedKmph\"]].reset_index()\ndf_temperature.rename(columns={'province': 'state'}, inplace=True)\ndf_temperature[\"Date\"] = pd.to_datetime(df_temperature['date'])\ndf_temperature['state'] = df_temperature['state'].fillna('')\n\n\ndf_temperature.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Date\"] = pd.to_datetime(df['Date'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(df_temperature, on=['country','Date'], how='left')\ndf.to_csv(\"countries_icu_temp.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression Model\nBy implementing a regression model which tries to use the country input variables to predict the most recent number of infections and deaths as target, we can extract the relative feature importance. This can be done pretty well with a Random Forest Regressor."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = df\nprint(train_data.shape)\ntrain_data.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(We only wish to have a look at countries which already have an infection ratio higher than 0, because the ones that aren't infected yet, might bias the feature importance)"},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 0\ntrain_data['infectionRate'] = round((train_data['ConfirmedCases']/train_data['population'])*100, 5)\ntrain_data = train_data[train_data['infectionRate'] >= threshold]\nprint(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_data[['Id', 'country', 'Date', 'ConfirmedCases',\n       'Fatalities', 'population', 'density', 'fertility', 'age',\n       'urban_percentage', 'icu', 'index', 'state', 'humidity',\n       'sunHour', 'tempC', 'windspeedKmph', 'infectionRate']]\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_data[[\"ConfirmedCases\", \"Fatalities\"]]\nX = train_data.drop([\"ConfirmedCases\", \"Fatalities\"],axis=1)\n\ndisplay(X.head())\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\ncm = train_data.corr()\nplt.figure(figsize=(20,10))\nsns.heatmap(cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train and Evaluate Model (Random Forest)"},{"metadata":{"trusted":true},"cell_type":"code","source":"fcols = ['population', 'density', 'fertility',\n       'age', 'urban_percentage', 'icu']\nmcols = ['humidity',\n       'sunHour', 'tempC', 'windspeedKmph']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnew = pd.DataFrame()\nfor country in df['country'].unique():\n    cdf = df.query('country == @country')\n#     cols = ['tempC  ' , 'windspeedKmph' , ]\n    for col in fcols :\n        cdf[col] = cdf[col].fillna(method = 'ffill')\n    for col in mcols:\n        cdf[col] = cdf[col].fillna(cdf.median())\n    new = new.append(cdf)\n        \ncdf.to_csv('./nitesh.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = new[['ConfirmedCases','Date', 'Fatalities', 'ForecastId',\n       'Id','country', 'population', 'density', 'fertility',\n       'age', 'urban_percentage', 'icu', 'index', 'state','humidity',\n       'sunHour', 'tempC', 'windspeedKmph']]\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_missing(df1):\n    df_train = df1\n    total = df_train.isnull().sum().sort_values(ascending=False)\n    percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)*100\n    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    print(missing_data.head(20))\n\n\n\nshow_missing(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TODO :\n* OHE\n* Model create"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n#scaler = StandardScaler()\n#X_scaled = scaler.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Split into training and evaluation data:\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\ndef rmsle(y_true, y_pred):\n    \"\"\"\n    Computes the Root Mean Squared Logarithmic Error of a prediction set.\n    params:\n        y_true: numpy array of ground truth\n        y_pred: numpy array of predictions\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n\nrmsle_scorer = make_scorer(rmsle)\n\nX_train, X_val, y_train, y_val = tts(X, y, test_size= 0.2, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_infected = DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\nscores = cross_val_score(model_infected, \n                      X_train,\n                      y_train[\"confirmed\"],\n                      cv=5, scoring=rmsle_scorer)\n\nprint(\"Cross Validation of Confirmed Cases: Mean = {}, std = {}\".format(scores.mean(), scores.std()))\nmodel_infected.fit(X_train, y_train[\"confirmed\"])\nresult_infected = rmsle(y_val[\"confirmed\"], model_infected.predict(X_val))\nprint(\"Validation Infected set RMSLE: {}\".format(result_infected))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_deaths = DecisionTreeRegressor(random_state=42, criterion=\"mae\")\n\nscores = cross_val_score(model_deaths, \n                      X_train,\n                      y_train[\"deaths\"],\n                      cv=5, scoring=rmsle_scorer)\n\nprint(\"Cross Validation of Fatal Cases: Mean = {}, std = {}\".format(scores.mean(), scores.std()))\nmodel_deaths.fit(X_train, y_train[\"deaths\"])\nresult_deaths = rmsle(y_val[\"deaths\"], model_deaths.predict(X_val))\nprint(\"Validation Death set RMSLE: {}\".format(result_deaths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final Evalutation\nprint(\"Final Validatio score: {}\".format(np.mean([result_infected, result_deaths])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Extract Features for Infections"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_infected = model_infected.fit(X, y[\"confirmed\"])\nmodel_deaths = model_deaths.fit(X, y[\"deaths\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_feature_importance(forest):\n    \"\"\"\n    Creates a sorted list of the feature importance of a decision tree algorithm.\n    Furthermore it plots it.\n    params:\n        forest: Decision Tree algorithm\n    \"\"\"\n    importances = forest.feature_importances_\n    indices = np.argsort(importances)[::-1]\n\n    # Print the feature ranking\n    print(\"Feature ranking:\")\n\n    for f in range(X.shape[1]):\n        print(\"{}, Feature: {}, Importance: {}\".format(f + 1, X.columns[indices[f]], importances[indices[f]]))\n\n    # Plot the feature importances of the forest\n    plt.figure(figsize=(20,10))\n    plt.title(\"Feature importances\")\n    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", align=\"center\")\n    plt.xticks(range(X.shape[1]),  X.columns[indices], rotation='vertical')\n    plt.xlim([-1, X.shape[1]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_feature_importance(model_infected)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the plot above we can see that many variables are positively correlated to the number of COVID19 infections such as: temperature, hours of sunlight, population, wind speed, humidity, and age. \n\nThese variables should be analyzed carefully as they are not necessaril causal. In terms of population for example, the more people there are in a country, the more likely they are to get infected.\nAlso, is it possible, that older people are more likely to be infected? Maybe they are also more likely to be tested, and hence confirmed.\nWeather conditions can help the virus to spread faster, such as temperature and humidity. It could be that the more hours of sunlight in a country, the more that people will want to be out and interact with social groups.\nThe percentage of people living in an urban area also has some importance because it signifies a higher density of people, making it easier to transmit the virus."},{"metadata":{},"cell_type":"markdown","source":"## Extract Features for Deaths"},{"metadata":{"trusted":true},"cell_type":"code","source":"show_feature_importance(model_deaths)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When inspecting the mortality, it appears as if weather conditions are more important than factors such as population, age, and urban percentage. Of course the standard deviation of prediction error should be taken into account, but from this data we can conclude that temperature and humidity are important features for predicting COVID19 mortality.\n\nFurthermore, with the current regression model, it does not seem that ICU beds per 1000 people are as important as expected."},{"metadata":{},"cell_type":"markdown","source":"## Create Submission\nThe test set for this week is from the 12th of March until the 23rd of April."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/covid19-global-forecasting-week-1/test.csv\")\ntest_df.rename(columns={'Date': 'date', \n                     'Province/State':'state',\n                     'Country/Region':'country',\n                    }, inplace=True)\ntest_df[\"date\"] = pd.to_datetime(test_df['date'])\ntest_df['state'] = test_df['state'].fillna('')\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_df = test_df.merge(df_temperature, on=['country','date', 'state'], how='left')\ntest_df = test_df.merge(countries_df, on=['country'], how='left')\ntest_df = test_df.merge(icu_cleaned, on=['country'], how='left')\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_df.set_index(\"ForecastId\").drop([\"Lat\", \"Long\", \"date\", \"state\", \"country\", \"index\"], axis=1).fillna(0)\n#X_test = scaler.fit_transform(X_test)\ny_pred_confirmed = model_infected.predict(X_test)\ny_pred_deaths = model_deaths.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"ForecastId\"] = test_df[\"ForecastId\"]\nsubmission = submission.set_index(['ForecastId'])\nsubmission[\"ConfirmedCases\"] = y_pred_confirmed.astype(int)\nsubmission[\"Fatalities\"] = y_pred_deaths.astype(int)\nsubmission.to_csv(\"submission.csv\")\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Time Series Analysis\nLet's now look into a time series analysis of the issue using Prophet and using the log of the confirmed cases in Italy as an example."},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\nm = Prophet()\nitaly_data = data[data['country']=='Italy']\nts_df = pd.concat([italy_data['date'], np.log(italy_data['confirmed']+1)], axis=1, keys=['ds', 'y'])\nts_df.head()\nm.fit(ts_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future = m.make_future_dataframe(periods=14)\nforecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(m, forecast)  # This returns a plotly Figure\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = data\nts_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df['infectionRate'] = round((ts_df['confirmed']/ts_df['population'])*100, 5)\nts_df = ts_df[ts_df['infectionRate'] >= threshold]\nts_df.index = ts_df.date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = ts_df.drop([\n                     \"country\", \n                     \"active\", \n                     \"recovered\", \n                     \"infectionRate\",\n                     \"state\",\n                     \"date\",\n                     \"Lat\",\n                     \"Long\",\n                     \"population\",\n                     \"density\",\n                     \"fertility\",\n                     \"age\",\n                     \"urban_percentage\",\n                     \"icu\",\n                     \"index\"\n                    ], axis= 1).dropna()\n\n#y = train_data[[\"confirmed\", \"deaths\"]]\n#X = train_data.drop([\"confirmed\", \"deaths\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_df = ts_df[:60]\nts_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_percentage = 0.75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = ts_df[:int(train_percentage*(len(ts_df)))]\nvalid = ts_df[int((1-train_percentage)*(len(ts_df))):]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.vector_ar.var_model import VAR\nmodel = VAR(endog=train)\nmodel_fit = model.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model_fit.forecast(model_fit.y, steps=len(valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pd.DataFrame(index=range(0,len(prediction)),columns=ts_df.columns)\nfor j in range(0,prediction.shape[1]):\n    for i in range(0, len(prediction)):\n        pred.iloc[i][j] = prediction[i][j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in ts_df.columns:\n    print('rmse value for', i, 'is : ', np.sqrt(mean_squared_error(pred[i], valid[i])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict = 14\nfuture_dt = pd.date_range(ts_df.last_valid_index(), periods=days_to_predict)\n\nmodel = VAR(endog=ts_df)\nmodel_fit = model.fit()\nyhat = model_fit.forecast(model_fit.y, steps=days_to_predict)\n\npred_df = pd.DataFrame(yhat, columns=ts_df.columns)\npred_df = pred_df.drop([\n                     \"humidity\", \n                     \"sunHour\", \n                     \"tempC\", \n                     \"windspeedKmph\"\n                    ], axis=1)\npred_df['confirmed'] = pred_df['confirmed'].astype(int)\npred_df['deaths'] = pred_df['deaths'].astype(int)\npred_df.index = future_dt\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We want to see if we can actually use the time series temperature data to find time-related insights. To do this we are looking into multivariate time series regression tools such as Vector Auto Regression (VAR)..."},{"metadata":{},"cell_type":"markdown","source":"# Thanks!\nIf you like this kernel, give us an upvote :)\nStay healthy, you beautiful people!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}